//! KFX Structure Tests
//!
//! These tests verify that generated KFX files have the correct internal structure
//! by comparing against reference files generated by Kindle Previewer.
//!
//! Key structural requirements discovered through analysis:
//! 1. $790 field must be present in paragraph content items
//! 2. Paragraphs should use nested structure ($269 containing $269 via $146)
//! 3. Text content should be properly chunked
//! 4. Container types ($270, $276) should be generated where appropriate

use boko::{read_epub, write_kfx};
use std::collections::HashMap;
use std::fs;
use std::path::Path;
use tempfile::TempDir;

const FIXTURES_DIR: &str = concat!(env!("CARGO_MANIFEST_DIR"), "/tests/fixtures");

fn fixture_path(name: &str) -> String {
    format!("{}/{}", FIXTURES_DIR, name)
}

/// Helper to read raw KFX and extract ION data for testing
/// Returns a simple representation of fragments
fn parse_kfx_fragments(path: &Path) -> Vec<KfxFragment> {
    let data = fs::read(path).expect("Failed to read KFX file");

    // Basic KFX container parsing
    if &data[0..4] != b"CONT" {
        panic!("Not a valid KFX container");
    }

    let header_len = u32::from_le_bytes(data[6..10].try_into().unwrap()) as usize;
    let ci_offset = u32::from_le_bytes(data[10..14].try_into().unwrap()) as usize;
    let ci_len = u32::from_le_bytes(data[14..18].try_into().unwrap()) as usize;

    // For now, use a simpler approach - just check if certain patterns exist in the raw data
    // A full ION parser would be needed for proper testing
    vec![] // Placeholder - we'll use Python scripts for detailed analysis
}

#[derive(Debug)]
struct KfxFragment {
    ftype: String,
    fid: String,
    has_790: bool,
    has_nested_269: bool,
}

// ============================================================================
// $790 Field Tests
// ============================================================================

/// Test that paragraph content items include the $790 field
/// Reference file has 240 occurrences of $790, generated should have similar
#[test]
fn test_kfx_paragraphs_have_790_field() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let kfx_path = temp_dir.path().join("test.kfx");

    write_kfx(&book, &kfx_path).expect("Failed to write KFX");

    // Use Python script to analyze the structure
    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            kfx_path.to_str().unwrap(),
            "--check",
            "790",
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    let stderr = String::from_utf8_lossy(&output.stderr);

    println!("stdout: {}", stdout);
    println!("stderr: {}", stderr);

    // Parse the count from output
    let count_790: usize = stdout
        .lines()
        .find(|l| l.starts_with("$790_count:"))
        .and_then(|l| l.split(':').nth(1))
        .and_then(|s| s.trim().parse().ok())
        .unwrap_or(0);

    // Reference has 240 occurrences - we should have a similar number
    // Allow some variance but should be > 100
    assert!(
        count_790 > 100,
        "Generated KFX should have >100 $790 fields, found {}",
        count_790
    );
}

// ============================================================================
// Nested Paragraph Structure Tests
// ============================================================================

/// Test that paragraphs use nested structure ($269 containing $269 via $146)
/// Reference has paragraphs with inner content arrays containing nested paragraphs
#[test]
fn test_kfx_paragraphs_have_nested_structure() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let kfx_path = temp_dir.path().join("test.kfx");

    write_kfx(&book, &kfx_path).expect("Failed to write KFX");

    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            kfx_path.to_str().unwrap(),
            "--check",
            "nested_paragraphs",
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    println!("stdout: {}", stdout);

    let nested_count: usize = stdout
        .lines()
        .find(|l| l.starts_with("nested_para_count:"))
        .and_then(|l| l.split(':').nth(1))
        .and_then(|s| s.trim().parse().ok())
        .unwrap_or(0);

    // Reference has nested paragraphs - we should too
    assert!(
        nested_count > 0,
        "Generated KFX should have nested paragraph structures, found {}",
        nested_count
    );
}

// ============================================================================
// Text Chunking Tests
// ============================================================================

/// Test that text content is properly chunked (not too large)
#[test]
fn test_kfx_text_chunking() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let kfx_path = temp_dir.path().join("test.kfx");

    write_kfx(&book, &kfx_path).expect("Failed to write KFX");

    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            kfx_path.to_str().unwrap(),
            "--check",
            "text_chunks",
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    println!("stdout: {}", stdout);

    // Check average chunk size
    let avg_chunk_size: usize = stdout
        .lines()
        .find(|l| l.starts_with("avg_chunk_size:"))
        .and_then(|l| l.split(':').nth(1))
        .and_then(|s| s.trim().parse().ok())
        .unwrap_or(0);

    // Chunks should be reasonably sized (not huge monolithic blocks)
    // Reference has ~4000 chars per chunk on average
    assert!(
        avg_chunk_size < 10000,
        "Text chunks should be <10000 chars on average, found {}",
        avg_chunk_size
    );
}

// ============================================================================
// Comparison with Reference Tests
// ============================================================================

/// Compare generated KFX structure against reference KFX
#[test]
fn test_kfx_structure_matches_reference() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let gen_path = temp_dir.path().join("generated.kfx");
    let ref_path = fixture_path("epictetus.kfx");

    write_kfx(&book, &gen_path).expect("Failed to write KFX");

    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            gen_path.to_str().unwrap(),
            "--reference",
            &ref_path,
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    let stderr = String::from_utf8_lossy(&output.stderr);

    println!("stdout: {}", stdout);
    if !stderr.is_empty() {
        println!("stderr: {}", stderr);
    }

    // Check for critical structural matches
    assert!(
        stdout.contains("790_match: true") || stdout.contains("790_match:true"),
        "Generated KFX should have similar $790 field count as reference.\n{}",
        stdout
    );

    assert!(
        stdout.contains("para_structure_match: true") || stdout.contains("para_structure_match:true"),
        "Generated KFX should have similar paragraph structure as reference.\n{}",
        stdout
    );
}

/// Test that storyline content item counts match reference
#[test]
fn test_kfx_storyline_content_counts() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let gen_path = temp_dir.path().join("generated.kfx");
    let ref_path = fixture_path("epictetus.kfx");

    write_kfx(&book, &gen_path).expect("Failed to write KFX");

    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            gen_path.to_str().unwrap(),
            "--reference",
            &ref_path,
            "--check",
            "storyline_counts",
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    println!("stdout: {}", stdout);

    // Parse storyline differences
    let total_diff: i32 = stdout
        .lines()
        .find(|l| l.starts_with("storyline_item_diff:"))
        .and_then(|l| l.split(':').nth(1))
        .and_then(|s| s.trim().parse().ok())
        .unwrap_or(999);

    // Allow small differences due to chunking, but should be close
    // Reference total: 523 items, should be within 20
    assert!(
        total_diff.abs() < 20,
        "Storyline content counts should be within 20 of reference, diff was {}",
        total_diff
    );
}

// ============================================================================
// Individual Fragment Type Tests
// ============================================================================

/// Test $269 (paragraph) fragment structure
#[test]
fn test_kfx_paragraph_fragment_structure() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let kfx_path = temp_dir.path().join("test.kfx");

    write_kfx(&book, &kfx_path).expect("Failed to write KFX");

    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            kfx_path.to_str().unwrap(),
            "--check",
            "para_fields",
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    println!("stdout: {}", stdout);

    // Check required fields in paragraph items
    // Reference paragraphs have: $155, $157, $159, $146 (with nested $269), $790, $142, $145
    let has_required_fields = stdout.contains("para_has_155: true")
        && stdout.contains("para_has_157: true")
        && stdout.contains("para_has_159: true");

    assert!(
        has_required_fields,
        "Paragraph items should have required fields ($155, $157, $159)"
    );
}

// ============================================================================
// Content Type Tests
// ============================================================================

/// Test that note references use $277 content type
/// Reference has 98 $277 items for endnote references
#[test]
fn test_kfx_note_reference_content_type() {
    let book = read_epub(fixture_path("epictetus.epub")).expect("Failed to read EPUB");

    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let kfx_path = temp_dir.path().join("test.kfx");

    write_kfx(&book, &kfx_path).expect("Failed to write KFX");

    let output = std::process::Command::new("python")
        .args([
            "scripts/kfx_structure_check.py",
            kfx_path.to_str().unwrap(),
            "--check",
            "content_types",
        ])
        .output()
        .expect("Failed to run structure check");

    let stdout = String::from_utf8_lossy(&output.stdout);
    println!("stdout: {}", stdout);

    // Reference has 98 $277 items for endnote references
    // We should have some $277 items if the EPUB has note references
    let count_277: usize = stdout
        .lines()
        .find(|l| l.starts_with("content_type_$277:"))
        .and_then(|l| l.split(':').nth(1))
        .and_then(|s| s.trim().parse().ok())
        .unwrap_or(0);

    // The epictetus.epub has endnote references, so we expect $277 items
    assert!(
        count_277 > 0,
        "Generated KFX should have $277 content type for note references, found {}",
        count_277
    );
}
